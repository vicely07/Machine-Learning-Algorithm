---
title: "Lab and HW 19"
author: "Vy Duong, Vi Ly, Shawn Olichwier"
date: "4/23/2019"
output:
  word_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

From HW and Lab 18, validate your best two models and compare.
```{r}
dat=read.csv("/Users/vyduong/Downloads/B13 copy.csv",header=T)
data.frame(dat)
m1=lm(y~x1+x6,data=dat)   # Model 1
m2=lm(y~x4,data=dat)      # Model 2

#inspection and comparison of coefficients
summary(m1)
summary(m2)
```
* We used all possible regressions to develop the best two models for the table B.13
* Model 1: $\hat{y}= 1103.27736 + 1.98197*x1 - 8.07277*x6$
* Model 2: $\hat{y}= 164.9901 + 21.4270*x4$
* Model 1 contains x1 and x6 while model 2 contains only x4. We will calculate the values of the PRESS statistics, R-squared prediction, and the VIF's for both models. 

```{r}
# VIF's
library(car)
vif(m1)
```

* For model 1, both VIFs are smaller than 5, indicating no potential problems with multicollinearity. However, for model 2, we cannot find the VIFs. The model contains only 1 term (x4).

```{r}
library(MPV)
anova1 = anova(m1)
sst1 = sum(anova1$'Sum Sq') #Calculate the total sum of squares
PRESS(m1) 
1-PRESS(m1)/(sst1)   # Calculate the predictive R^2

anova2 = anova(m2)
sst2 = sum(anova2$'Sum Sq') #Calculate the total sum of squares
PRESS(m2)
1-PRESS(m2)/(sst2)   # Calculate the predictive R^2
```
* For model 1, the PRESS statistic is 48396.43 and the predictive R-squared is 0.9951272
* For model 2, the PRESS statistic is 106716.6 and  the predictive R-squared is 0.9892553
* According to the above result, model 1 have a larger value of the predictive R-square. It means model 1 is better than model 2. 

```{r}
library(cvTools)
folds <- cvFolds(nrow(dat), K = 4, R =15) #type = "random", "consecutive", "interleaved"
cvfit1 <- cvLm(m1, cost = rtmspe,folds = folds)
cvfit2 <- cvLm(m2, cost = rtmspe,folds = folds) 
cvFits <- cvSelect(LS1 = cvfit1, LS2 =cvfit2)
cvFits
densityplot(cvFits) #plot combined results
```

* We split the data by running the cvFolds, with K = 4 (split the observations into 4 groups) and R = 15 (repeat K-fold cross-validation by 15). It gives us the result with model 1 is the best model. 
* According to the regression models, the PRESS statistics, the R-squared predictions, the VIF's, and the data splitting for both models, model 1 is the best model. 
